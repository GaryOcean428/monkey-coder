{
  "$schema": "https://json-schema.org/draft-07/schema#",
  "version": "2026-02-11",
  "updated": "2026-02-11T00:00:00Z",
  "sources": [
    "https://platform.openai.com/docs/models",
    "https://platform.claude.com/docs/en/about-claude/models/overview",
    "https://platform.claude.com/docs/en/about-claude/models/whats-new-claude-4-6",
    "https://ai.google.dev/gemini-api/docs/models",
    "https://ai.google.dev/gemini-api/docs/gemini-3",
    "https://ai.google.dev/gemini-api/docs/deep-research",
    "https://ai.google.dev/gemini-api/docs/live",
    "https://ai.google.dev/gemini-api/docs/computer-use",
    "https://docs.x.ai/docs/models",
    "https://console.groq.com/docs/models"
  ],
  "models": [
    {
      "id": "claude-haiku-4-5",
      "provider": "anthropic",
      "family": "claude-4.5",
      "context_limit": 200000,
      "output_limit": 64000,
      "cost_input": 1,
      "cost_output": 5,
      "capabilities": ["code", "reasoning", "vision", "tools", "context_caching", "citations", "pdf"],
      "tools": ["bash", "code_execution", "text_editor", "web_fetch", "web_search", "tool_search", "mcp"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 300,
      "avg_latency_p95": 600,
      "knowledge_cutoff": "February 2025",
      "released": "2025-10-01",
      "status": "production",
      "alias_for": "claude-haiku-4-5-20251001",
      "description": "Alias for latest Claude Haiku 4.5 model"
    },
    {
      "id": "claude-haiku-4-5-20251001",
      "provider": "anthropic",
      "family": "claude-4.5",
      "context_limit": 200000,
      "output_limit": 64000,
      "cost_input": 1,
      "cost_output": 5,
      "capabilities": ["code", "reasoning", "vision", "tools", "context_caching", "citations", "pdf"],
      "tools": ["bash", "code_execution", "text_editor", "web_fetch", "web_search", "tool_search", "mcp"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 300,
      "avg_latency_p95": 600,
      "knowledge_cutoff": "February 2025",
      "released": "2025-10-01",
      "status": "production",
      "description": "Fastest model with near-frontier intelligence"
    },
    {
      "id": "claude-opus-4-5",
      "provider": "anthropic",
      "family": "claude-4.5",
      "context_limit": 200000,
      "output_limit": 64000,
      "cost_input": 5,
      "cost_output": 25,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "tools",
        "extended_thinking",
        "context_caching",
        "context_editing",
        "citations",
        "pdf"
      ],
      "tools": [
        "bash",
        "code_execution",
        "computer_use",
        "text_editor",
        "web_fetch",
        "web_search",
        "memory",
        "tool_search",
        "mcp"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 800,
      "avg_latency_p95": 1600,
      "knowledge_cutoff": "May 2025",
      "released": "2025-11-01",
      "status": "production",
      "alias_for": "claude-opus-4-5-20251101",
      "description": "Alias for latest Claude Opus 4.5 model"
    },
    {
      "id": "claude-opus-4-5-20251101",
      "provider": "anthropic",
      "family": "claude-4.5",
      "context_limit": 200000,
      "output_limit": 64000,
      "cost_input": 5,
      "cost_output": 25,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "tools",
        "extended_thinking",
        "context_caching",
        "context_editing",
        "citations",
        "pdf"
      ],
      "tools": [
        "bash",
        "code_execution",
        "computer_use",
        "text_editor",
        "web_fetch",
        "web_search",
        "memory",
        "tool_search",
        "mcp"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 800,
      "avg_latency_p95": 1600,
      "knowledge_cutoff": "May 2025",
      "released": "2025-11-01",
      "status": "production",
      "description": "Premium model combining maximum intelligence with practical performance"
    },
    {
      "id": "claude-opus-4-6",
      "provider": "anthropic",
      "family": "claude-4.6",
      "context_limit": 200000,
      "context_limit_extended": 1000000,
      "output_limit": 128000,
      "cost_input": 5,
      "cost_output": 25,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "computer_use",
        "extended_thinking",
        "adaptive_thinking",
        "tools",
        "context_caching",
        "context_editing",
        "citations",
        "pdf",
        "compaction",
        "fast_mode"
      ],
      "tools": [
        "bash",
        "code_execution",
        "computer_use",
        "text_editor",
        "web_fetch",
        "web_search",
        "memory",
        "tool_search",
        "mcp"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 700,
      "avg_latency_p95": 1400,
      "knowledge_cutoff": "May 2025",
      "released": "2026-02-05",
      "status": "production",
      "description": "Most intelligent Claude model with adaptive thinking, 128K output, and 1M context beta"
    },
    {
      "id": "claude-sonnet-4-5",
      "provider": "anthropic",
      "family": "claude-4.5",
      "context_limit": 200000,
      "context_limit_extended": 1000000,
      "output_limit": 64000,
      "cost_input": 3,
      "cost_output": 15,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "computer_use",
        "extended_thinking",
        "tools",
        "context_caching",
        "context_editing",
        "citations",
        "pdf"
      ],
      "tools": [
        "bash",
        "code_execution",
        "computer_use",
        "text_editor",
        "web_fetch",
        "web_search",
        "memory",
        "tool_search",
        "mcp"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 600,
      "avg_latency_p95": 1200,
      "knowledge_cutoff": "January 2025",
      "released": "2025-09-29",
      "status": "production",
      "alias_for": "claude-sonnet-4-5-20250929",
      "description": "Alias for latest Claude Sonnet 4.5 model"
    },
    {
      "id": "claude-sonnet-4-5-20250929",
      "provider": "anthropic",
      "family": "claude-4.5",
      "context_limit": 200000,
      "context_limit_extended": 1000000,
      "output_limit": 64000,
      "cost_input": 3,
      "cost_output": 15,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "computer_use",
        "extended_thinking",
        "tools",
        "context_caching",
        "context_editing",
        "citations",
        "pdf"
      ],
      "tools": [
        "bash",
        "code_execution",
        "computer_use",
        "text_editor",
        "web_fetch",
        "web_search",
        "memory",
        "tool_search",
        "mcp"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 600,
      "avg_latency_p95": 1200,
      "knowledge_cutoff": "January 2025",
      "released": "2025-09-29",
      "status": "production",
      "description": "Smart model for complex agents and coding with computer use capabilities"
    },
    {
      "id": "gemini-2.5-flash",
      "provider": "google",
      "family": "gemini-2.5",
      "context_limit": 1000000,
      "output_limit": 65000,
      "cost_input": 0.3,
      "cost_output": 1.2,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "audio",
        "tools",
        "live_api",
        "context_caching",
        "google_search",
        "file_search",
        "code_execution"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 400,
      "avg_latency_p95": 800,
      "knowledge_cutoff": "January 2025",
      "released": "2025-06-01",
      "status": "production",
      "description": "Best price-performance for large scale, low-latency, and agentic tasks"
    },
    {
      "id": "gemini-2.5-flash-lite",
      "provider": "google",
      "family": "gemini-2.5",
      "context_limit": 1000000,
      "output_limit": 65000,
      "cost_input": 0.018,
      "cost_output": 0.075,
      "capabilities": ["code", "reasoning", "vision", "tools", "context_caching"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 300,
      "avg_latency_p95": 600,
      "knowledge_cutoff": "January 2025",
      "released": "2025-06-01",
      "status": "production",
      "description": "Fastest flash model optimized for cost-efficiency and high throughput"
    },
    {
      "id": "gemini-2.5-pro",
      "provider": "google",
      "family": "gemini-2.5",
      "context_limit": 1000000,
      "output_limit": 65000,
      "cost_input": 1.25,
      "cost_output": 5,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "audio",
        "tools",
        "live_api",
        "context_caching",
        "google_search",
        "file_search",
        "code_execution"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 700,
      "avg_latency_p95": 1400,
      "knowledge_cutoff": "January 2025",
      "released": "2025-06-01",
      "status": "production",
      "description": "Advanced thinking model for complex reasoning in code, math, STEM"
    },
    {
      "id": "gemini-3-flash-preview",
      "provider": "google",
      "family": "gemini-3",
      "context_limit": 1000000,
      "output_limit": 64000,
      "cost_input": 0.5,
      "cost_output": 3,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "audio",
        "tools",
        "thinking_levels",
        "thought_signatures",
        "context_caching",
        "google_search",
        "file_search",
        "code_execution"
      ],
      "thinking_levels": ["minimal", "low", "medium", "high"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 400,
      "avg_latency_p95": 800,
      "knowledge_cutoff": "January 2025",
      "released": "2025-12+",
      "status": "preview",
      "description": "Most balanced model built for speed, scale, and frontier intelligence"
    },
    {
      "id": "gemini-3-pro-image-preview",
      "provider": "google",
      "family": "gemini-3",
      "context_limit": 65000,
      "output_limit": 32000,
      "cost_input": 2,
      "cost_output": 4,
      "capabilities": ["code", "reasoning", "vision", "image_generation", "tools", "context_caching", "google_search"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 800,
      "avg_latency_p95": 1600,
      "knowledge_cutoff": "January 2025",
      "released": "2026-01+",
      "status": "preview",
      "description": "Gemini 3 Pro variant specialized for native image generation and editing"
    },
    {
      "id": "gemini-3-pro-preview",
      "provider": "google",
      "family": "gemini-3",
      "context_limit": 1000000,
      "output_limit": 64000,
      "cost_input": 2,
      "cost_output": 12,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "audio",
        "tools",
        "deep_research",
        "live_api",
        "computer_use",
        "thinking_levels",
        "thought_signatures",
        "context_caching",
        "google_search",
        "file_search",
        "code_execution"
      ],
      "thinking_levels": ["low", "high"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 700,
      "avg_latency_p95": 1400,
      "knowledge_cutoff": "January 2025",
      "released": "2025-11+",
      "status": "preview",
      "description": "Best for multimodal understanding, most powerful agentic and vibe-coding model"
    },
    {
      "id": "groq/compound",
      "provider": "groq",
      "family": "compound",
      "context_limit": 131072,
      "output_limit": 8192,
      "cost_input": 0.27,
      "cost_output": 1.1,
      "capabilities": ["code", "reasoning", "tools", "web_search", "code_execution", "agentic"],
      "tools": ["web_search", "code_execution"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 100,
      "avg_latency_p95": 200,
      "throughput_tokens_per_sec": 450,
      "knowledge_cutoff": "December 2024",
      "released": "2025+",
      "status": "production",
      "description": "AI system with built-in tools (web search, code execution)"
    },
    {
      "id": "llama-3.3-70b-versatile",
      "provider": "groq",
      "family": "llama-3",
      "context_limit": 131072,
      "output_limit": 32768,
      "cost_input": 0.59,
      "cost_output": 0.79,
      "capabilities": ["code", "reasoning", "tools"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 50,
      "avg_latency_p95": 100,
      "throughput_tokens_per_sec": 280,
      "knowledge_cutoff": "December 2024",
      "released": "2024+",
      "status": "production",
      "description": "Production-ready on Groq LPUs with ultra-fast inference"
    },
    {
      "id": "llama-3.1-8b-instant",
      "provider": "groq",
      "family": "llama-3",
      "context_limit": 131072,
      "output_limit": 8192,
      "cost_input": 0.05,
      "cost_output": 0.08,
      "capabilities": ["code", "reasoning", "tools"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 30,
      "avg_latency_p95": 60,
      "throughput_tokens_per_sec": 750,
      "knowledge_cutoff": "December 2024",
      "released": "2024+",
      "status": "production",
      "description": "Fast, lightweight production model on Groq LPUs"
    },
    {
      "id": "gpt-4.1",
      "provider": "openai",
      "family": "gpt-4.1",
      "context_limit": 200000,
      "output_limit": 64000,
      "cost_input": 2.5,
      "cost_output": 10,
      "capabilities": ["code", "reasoning", "vision", "tools", "function_calling"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 350,
      "avg_latency_p95": 700,
      "knowledge_cutoff": "January 2025",
      "released": "2025-01-15",
      "status": "production",
      "description": "Smartest non-reasoning model"
    },
    {
      "id": "gpt-4.1-mini",
      "provider": "openai",
      "family": "gpt-4.1",
      "context_limit": 1000000,
      "output_limit": 64000,
      "cost_input": 0.12,
      "cost_output": 0.48,
      "capabilities": ["code", "reasoning", "vision", "tools", "function_calling"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 250,
      "avg_latency_p95": 500,
      "knowledge_cutoff": "January 2025",
      "released": "2025-01-15",
      "status": "production",
      "description": "Smaller, faster version of GPT-4.1"
    },
    {
      "id": "gpt-4.1-nano",
      "provider": "openai",
      "family": "gpt-4.1",
      "context_limit": 1000000,
      "output_limit": 64000,
      "cost_input": 0.05,
      "cost_output": 0.2,
      "capabilities": ["code", "reasoning", "tools", "function_calling"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 200,
      "avg_latency_p95": 400,
      "knowledge_cutoff": "January 2025",
      "released": "2025-01-15",
      "status": "production",
      "description": "Fastest, most cost-efficient version of GPT-4.1"
    },
    {
      "id": "gpt-5",
      "provider": "openai",
      "family": "gpt-5",
      "context_limit": 200000,
      "output_limit": 64000,
      "cost_input": 2.5,
      "cost_output": 10,
      "capabilities": ["code", "reasoning", "vision", "tools", "function_calling", "prompt_caching"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 400,
      "avg_latency_p95": 800,
      "knowledge_cutoff": "January 2025",
      "released": "2025-01-15",
      "status": "production",
      "description": "Latest flagship GPT model with advanced multimodal capabilities"
    },
    {
      "id": "gpt-5-mini",
      "provider": "openai",
      "family": "gpt-5",
      "context_limit": 200000,
      "output_limit": 64000,
      "cost_input": 0.15,
      "cost_output": 0.6,
      "capabilities": ["code", "reasoning", "tools", "function_calling", "prompt_caching"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 250,
      "avg_latency_p95": 500,
      "knowledge_cutoff": "January 2025",
      "released": "2025+",
      "status": "production",
      "description": "Faster, cost-efficient version of GPT-5 for well-defined tasks"
    },
    {
      "id": "gpt-5-nano",
      "provider": "openai",
      "family": "gpt-5",
      "context_limit": 200000,
      "output_limit": 64000,
      "cost_input": 0.05,
      "cost_output": 0.2,
      "capabilities": ["code", "reasoning", "tools"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 150,
      "avg_latency_p95": 300,
      "knowledge_cutoff": "January 2025",
      "released": "2025+",
      "status": "production",
      "description": "Fastest, most cost-efficient version of GPT-5"
    },
    {
      "id": "gpt-5.2",
      "provider": "openai",
      "family": "gpt-5",
      "context_limit": 400000,
      "output_limit": 128000,
      "cost_input": 1.75,
      "cost_output": 14,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "tools",
        "function_calling",
        "structured_outputs",
        "prompt_caching"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 400,
      "avg_latency_p95": 800,
      "knowledge_cutoff": "August 2025",
      "released": "2025-12-11",
      "status": "production",
      "description": "Best model for coding and agentic tasks across industries"
    },
    {
      "id": "gpt-5.2-codex",
      "provider": "openai",
      "family": "gpt-5",
      "context_limit": 400000,
      "output_limit": 128000,
      "cost_input": 1.75,
      "cost_output": 14,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "tools",
        "function_calling",
        "structured_outputs",
        "prompt_caching"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 500,
      "avg_latency_p95": 1000,
      "knowledge_cutoff": "August 2025",
      "released": "2026-01-14",
      "status": "production",
      "description": "Agentic coding specialist with context compaction and SWE-bench Pro 56.4%"
    },
    {
      "id": "gpt-5.2-pro",
      "provider": "openai",
      "family": "gpt-5",
      "context_limit": 400000,
      "output_limit": 128000,
      "cost_input": 21,
      "cost_output": 168,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "tools",
        "function_calling",
        "structured_outputs",
        "prompt_caching"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 600,
      "avg_latency_p95": 1200,
      "knowledge_cutoff": "August 2025",
      "released": "2025-12-11",
      "status": "production",
      "description": "Version of GPT-5.2 that produces smarter and more precise responses"
    },
    {
      "id": "gpt-5.1",
      "provider": "openai",
      "family": "gpt-5",
      "context_limit": 400000,
      "output_limit": 128000,
      "cost_input": 1.25,
      "cost_output": 10,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "tools",
        "function_calling",
        "prompt_caching",
        "structured_outputs"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 380,
      "avg_latency_p95": 750,
      "knowledge_cutoff": "January 2026",
      "released": "2025-11-13",
      "status": "production",
      "description": "Latest flagship GPT model with 400K context and advanced reasoning"
    },
    {
      "id": "gpt-5.3-codex",
      "provider": "openai",
      "family": "gpt-5",
      "context_limit": 400000,
      "output_limit": 128000,
      "cost_input": 2.0,
      "cost_output": 14,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "tools",
        "function_calling",
        "prompt_caching",
        "structured_outputs"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 300,
      "avg_latency_p95": 600,
      "knowledge_cutoff": "January 2026",
      "released": "2026-02-05",
      "status": "production",
      "description": "Latest Codex model for agentic coding, 25% faster than GPT-5.2-Codex"
    },
    {
      "id": "gpt-oss-120b",
      "provider": "openai",
      "family": "gpt-oss",
      "context_limit": 131072,
      "output_limit": 65536,
      "cost_input": 0,
      "cost_output": 0,
      "capabilities": ["code", "reasoning", "tools"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 400,
      "avg_latency_p95": 800,
      "knowledge_cutoff": "October 2024",
      "released": "2025+",
      "status": "production",
      "license": "Apache 2.0",
      "description": "Most powerful open-weight model"
    },
    {
      "id": "gpt-oss-20b",
      "provider": "openai",
      "family": "gpt-oss",
      "context_limit": 131072,
      "output_limit": 65536,
      "cost_input": 0,
      "cost_output": 0,
      "capabilities": ["code", "reasoning", "tools"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 200,
      "avg_latency_p95": 400,
      "knowledge_cutoff": "October 2024",
      "released": "2025+",
      "status": "production",
      "license": "Apache 2.0",
      "description": "Medium-sized open-weight model for low latency"
    },
    {
      "id": "o3-deep-research",
      "provider": "openai",
      "family": "o3",
      "context_limit": 200000,
      "output_limit": 100000,
      "cost_input": 15,
      "cost_output": 60,
      "capabilities": ["reasoning", "deep_research", "web_search", "tools"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 5000,
      "avg_latency_p95": 15000,
      "knowledge_cutoff": "January 2025",
      "released": "2025+",
      "status": "production",
      "description": "Most powerful deep research model with autonomous multi-step research"
    },
    {
      "id": "o3-pro",
      "provider": "openai",
      "family": "o3",
      "context_limit": 200000,
      "output_limit": 100000,
      "cost_input": 15,
      "cost_output": 60,
      "capabilities": ["reasoning", "tools"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 3000,
      "avg_latency_p95": 8000,
      "knowledge_cutoff": "January 2025",
      "released": "2025-01-01",
      "status": "production",
      "description": "Version of o3 with more compute for better responses"
    },
    {
      "id": "o3",
      "provider": "openai",
      "family": "o3",
      "context_limit": 200000,
      "output_limit": 100000,
      "cost_input": 2,
      "cost_output": 8,
      "capabilities": ["reasoning", "vision", "tools", "function_calling", "structured_outputs"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 2000,
      "avg_latency_p95": 6000,
      "knowledge_cutoff": "January 2025",
      "released": "2025-01-15",
      "status": "production",
      "description": "Reasoning model for complex tasks, succeeded by GPT-5"
    },
    {
      "id": "o3-mini",
      "provider": "openai",
      "family": "o3",
      "context_limit": 200000,
      "output_limit": 100000,
      "cost_input": 0.6,
      "cost_output": 2.4,
      "capabilities": ["reasoning", "tools", "function_calling", "structured_outputs"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 1000,
      "avg_latency_p95": 3000,
      "knowledge_cutoff": "January 2025",
      "released": "2025-01-15",
      "status": "production",
      "description": "A small model alternative to o3"
    },
    {
      "id": "o4-mini",
      "provider": "openai",
      "family": "o4",
      "context_limit": 200000,
      "output_limit": 100000,
      "cost_input": 1.1,
      "cost_output": 4.4,
      "capabilities": ["reasoning", "vision", "tools", "function_calling", "structured_outputs"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 1500,
      "avg_latency_p95": 4000,
      "knowledge_cutoff": "January 2025",
      "released": "2025-01-15",
      "status": "production",
      "description": "Fast, cost-efficient reasoning model, succeeded by GPT-5 mini"
    },
    {
      "id": "o4-mini-deep-research",
      "provider": "openai",
      "family": "o4",
      "context_limit": 200000,
      "output_limit": 100000,
      "cost_input": 3,
      "cost_output": 12,
      "capabilities": ["reasoning", "deep_research", "web_search", "tools"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 3000,
      "avg_latency_p95": 9000,
      "knowledge_cutoff": "January 2025",
      "released": "2025+",
      "status": "production",
      "description": "Faster, more affordable deep research model"
    },
    {
      "id": "grok-3",
      "provider": "xai",
      "family": "grok-3",
      "context_limit": 131072,
      "output_limit": 32768,
      "cost_input": 5,
      "cost_output": 15,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "tools",
        "web_search",
        "x_search",
        "code_execution",
        "prompt_caching"
      ],
      "tools": [
        "web_search",
        "x_search",
        "code_execution",
        "document_search",
        "view_image",
        "view_x_video",
        "collections_search",
        "remote_mcp"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 600,
      "avg_latency_p95": 1200,
      "knowledge_cutoff": "November 2024",
      "released": "2024-11+",
      "status": "production",
      "description": "Flagship model with vision and multimodal capabilities"
    },
    {
      "id": "grok-3-mini",
      "provider": "xai",
      "family": "grok-3",
      "context_limit": 131072,
      "output_limit": 32768,
      "cost_input": 0.5,
      "cost_output": 1.5,
      "capabilities": ["code", "reasoning", "tools", "web_search", "code_execution", "prompt_caching"],
      "tools": ["web_search", "x_search", "code_execution", "document_search", "collections_search"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 300,
      "avg_latency_p95": 600,
      "knowledge_cutoff": "November 2024",
      "released": "2024-11+",
      "status": "production",
      "description": "Smaller, faster version of Grok 3"
    },
    {
      "id": "grok-4",
      "provider": "xai",
      "family": "grok-4",
      "context_limit": 131072,
      "output_limit": 32768,
      "cost_input": 10,
      "cost_output": 20,
      "capabilities": ["reasoning", "vision", "tools", "web_search", "x_search", "code_execution", "prompt_caching"],
      "tools": [
        "web_search",
        "x_search",
        "code_execution",
        "document_search",
        "view_image",
        "collections_search",
        "remote_mcp"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 800,
      "avg_latency_p95": 1600,
      "knowledge_cutoff": "November 2024",
      "released": "2025+",
      "status": "production",
      "description": "Reasoning model (no non-reasoning mode)"
    },
    {
      "id": "grok-code-fast-1",
      "provider": "xai",
      "family": "grok-code",
      "context_limit": 256000,
      "output_limit": 10000,
      "cost_input": 0.2,
      "cost_output": 1.5,
      "capabilities": [
        "code",
        "reasoning",
        "vision",
        "tools",
        "function_calling",
        "structured_outputs",
        "prompt_caching"
      ],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 200,
      "avg_latency_p95": 400,
      "knowledge_cutoff": "November 2024",
      "released": "2025-08-28",
      "status": "production",
      "description": "Speedy and economical 314B MoE reasoning model optimized for agentic coding"
    },
    {
      "id": "grok-4.1-fast-non-reasoning",
      "provider": "xai",
      "family": "grok-4.1",
      "context_limit": 1000000,
      "output_limit": 64000,
      "cost_input": 0.5,
      "cost_output": 2,
      "capabilities": ["code", "vision", "tools", "web_search", "x_search", "prompt_caching"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 200,
      "avg_latency_p95": 400,
      "knowledge_cutoff": "January 2026",
      "released": "2026-01-10",
      "status": "production",
      "description": "Instant response model for standard tasks"
    },
    {
      "id": "grok-4.1-fast-reasoning",
      "provider": "xai",
      "family": "grok-4.1",
      "context_limit": 2000000,
      "output_limit": 100000,
      "cost_input": 2,
      "cost_output": 10,
      "capabilities": [
        "reasoning",
        "vision",
        "tools",
        "web_search",
        "x_search",
        "code_execution",
        "silent_observer",
        "prompt_caching"
      ],
      "tools": ["web_search", "x_search", "code_execution", "document_search", "remote_mcp"],
      "supports_streaming": true,
      "supports_tools": true,
      "avg_latency_p50": 400,
      "avg_latency_p95": 800,
      "knowledge_cutoff": "January 2026",
      "released": "2026-01-10",
      "status": "production",
      "description": "Fast reasoning model with 2M context window, optimized for background observation and context augmentation"
    }
  ],
  "capabilities_definitions": {
    "code": "Code generation, understanding, and debugging",
    "reasoning": "Advanced logical and analytical reasoning",
    "vision": "Image understanding and analysis",
    "audio": "Audio input and/or output capabilities",
    "tools": "Function/tool calling support",
    "function_calling": "Native function calling with parallel execution",
    "structured_outputs": "JSON schema validation for responses",
    "computer_use": "Browser automation and UI control",
    "extended_thinking": "Internal reasoning before responding (up to 128K tokens)",
    "adaptive_thinking": "Dynamic reasoning that adjusts depth based on problem complexity (Opus 4.6+)",
    "compaction": "Server-side context summarization for effectively infinite conversations",
    "image_generation": "Native image generation from text descriptions",
    "deep_research": "Autonomous multi-step research with web search",
    "live_api": "Real-time audio/video streaming",
    "thinking_levels": "Control reasoning depth (minimal/low/medium/high)",
    "thought_signatures": "Maintain reasoning context across turns",
    "context_caching": "Cache frequent prompt segments for cost reduction",
    "context_editing": "Modify cached context without full re-upload",
    "citations": "Automatic source attribution in responses",
    "pdf": "Native PDF document processing",
    "google_search": "Real-time Google Search integration",
    "file_search": "Query uploaded documents",
    "code_execution": "Built-in code interpreter (Python)",
    "web_search": "Internet search and page browsing",
    "x_search": "Search X (Twitter) posts, users, threads",
    "agentic": "Built-in agentic system with autonomous tool use",
    "prompt_caching": "Automatic input caching for repeated prompt prefixes (reduces cost on subsequent calls)",
    "fast_mode": "High-speed output tier (2.5x faster) with same model quality"
  },
  "tool_definitions": {
    "bash": "Execute bash commands (Claude)",
    "code_execution": "Python code interpreter",
    "computer_use": "Browser automation with mouse/keyboard control",
    "text_editor": "Text file manipulation (Claude)",
    "web_fetch": "Fetch content from URLs (Claude)",
    "web_search": "Internet search",
    "memory": "Persistent memory across conversations (Claude)",
    "tool_search": "Search available tools (Claude)",
    "mcp": "Model Context Protocol connector",
    "remote_mcp": "Remote MCP tools",
    "x_search": "Search X (Twitter) content",
    "document_search": "Search uploaded documents",
    "view_image": "Analyze images within search results",
    "view_x_video": "Analyze videos within X posts",
    "collections_search": "Search knowledge base collections",
    "google_search": "Google Search grounding",
    "file_search": "Search uploaded files"
  },
  "deprecations": [
    {
      "id": "grok-2",
      "replacement_ids": ["grok-4.1-fast-reasoning", "grok-3"],
      "note": "No longer supported"
    },
    {
      "id": "gpt-4o",
      "replacement_ids": ["gpt-4.1"],
      "note": "Superseded by GPT-4.1 family"
    },
    {
      "id": "gpt-4o-mini",
      "replacement_ids": ["gpt-4.1-mini"],
      "note": "Superseded by GPT-4.1 Mini"
    },
    {
      "id": "gpt-4-turbo",
      "replacement_ids": ["gpt-4.1"],
      "note": "Old generation"
    },
    {
      "id": "gpt-4",
      "replacement_ids": ["gpt-4.1"],
      "note": "Old generation"
    },
    {
      "id": "gpt-3.5-turbo",
      "replacement_ids": ["gpt-4.1-nano"],
      "note": "Legacy model"
    },
    {
      "id": "o1-mini",
      "replacement_ids": ["o4-mini"],
      "note": "Explicitly deprecated by OpenAI"
    },
    {
      "id": "o1-preview",
      "replacement_ids": ["o3"],
      "note": "Explicitly deprecated by OpenAI"
    },
    {
      "id": "claude-3-5-sonnet-*",
      "replacement_ids": ["claude-sonnet-4-5"],
      "note": "Old generation — migrate to Claude 4.5/4.6"
    },
    {
      "id": "claude-3-5-haiku-*",
      "replacement_ids": ["claude-haiku-4-5"],
      "note": "Old generation — migrate to Claude 4.5/4.6"
    },
    {
      "id": "claude-3-7-sonnet-*",
      "replacement_ids": ["claude-sonnet-4-5"],
      "note": "Old generation — migrate to Claude 4.5/4.6"
    },
    {
      "id": "claude-opus-4-20250514",
      "replacement_ids": ["claude-opus-4-6"],
      "note": "Superseded by Opus 4.6"
    },
    {
      "id": "claude-sonnet-4-20250514",
      "replacement_ids": ["claude-sonnet-4-5"],
      "note": "Superseded by Sonnet 4.5"
    },
    {
      "id": "claude-opus-4-1-20250805",
      "replacement_ids": ["claude-opus-4-6"],
      "note": "Superseded by Opus 4.6"
    },
    {
      "id": "gemini-2.0-flash",
      "replacement_ids": ["gemini-2.5-flash"],
      "note": "Deprecated by Google — shutting down March 31, 2026"
    },
    {
      "id": "gemini-1.5-*",
      "replacement_ids": ["gemini-2.5-pro", "gemini-2.5-flash"],
      "note": "Old generation"
    }
  ]
}
